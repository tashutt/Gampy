#!/usr/bin/env python3
import os
import numpy as np
from pathlib import Path

# User Guide:
# 1. Set the PARTICLES and MATERIAL. [photons/electrons]   [LAr]
# 2. Adjust the MAX_BATCH variable to control the maximum number of tracks per batch.
# 3. Modify the TRACK_CONFIGS list to specify the energies and number of tracks for each configuration.


# ========== USER SETTINGS ==========
PARTICLES = 'electrons'
MATERIAL  = 'LAr'
MAX_BATCH = 250

TRACK_CONFIGS = [
    {'energy': 100, 'num_tracks': 100},
    {'energy': 300, 'num_tracks': 100},
    {'energy': 500, 'num_tracks': 100},
    {'energy': 1000, 'num_tracks': 100},
    {'energy': 3000, 'num_tracks': 100},
    {'energy': 5000, 'num_tracks': 100},
    {'energy': 10000, 'num_tracks': 100},
    {'energy': 20000, 'num_tracks': 100},
    {'energy': 50000, 'num_tracks': 100}
]

# ========== DIRECTORIES ==========
BASE_DIR = os.curdir
EXECUTABLE_PATH = f'{BASE_DIR}/execute'
OUTPUT_PATH = f'{BASE_DIR}/Tracks'
SBATCH_SCRIPT_PATH = f'{BASE_DIR}/sbatch_scripts'

# ========== VALIDATIONS ==========
if not os.path.exists(EXECUTABLE_PATH):
    raise FileNotFoundError(f"Executable path '{EXECUTABLE_PATH}' does not exist. Please check the path.")
# check if Gampy is installed
try:
    import Gampy
except ImportError:
    raise ImportError("Gampy is not installed. Please install it")

# if SBATCH_SCRIPT_PATH exists, delete it
if os.path.exists(SBATCH_SCRIPT_PATH):
    print(f"‚ö†Ô∏è Warning: The directory '{SBATCH_SCRIPT_PATH}' already exists. It will be overwritten.")
    os.system(f"rm -rf {SBATCH_SCRIPT_PATH}")

# if OUTPUT_PATH exists, create a new one with a timestamp
if os.path.exists(OUTPUT_PATH):
    timestamp = np.datetime64('now', 's').astype(str)
    new_output_path = f"{OUTPUT_PATH}_{timestamp}"
    print(f"‚ö†Ô∏è Warning: The directory '{OUTPUT_PATH}' already exists. Creating a new one: '{new_output_path}'")
    OUTPUT_PATH = new_output_path
    os.makedirs(OUTPUT_PATH, exist_ok=True)

# ========== TEMPLATES ==========
PYTHON_TEMPLATE = """#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# This script was generated automatically. Do not edit manually.
# Generated by genTracks.py

import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from Gampy.tools import penelope_tools
import numpy as np

steering = {{
    'particles': '{particles}',
    'material': '{material}',
    'folder_tag': '{tag}',
    'energies': np.array([{energy}], dtype=float),
    'num_tracks': np.array([{n_tracks}], dtype=int),
    'max_num_tracks_batch': {max_batch}
}}

p = {{
    'executable': '{exec_path}',
    'output': '{output_path}'
}}

penelope_tools.batch_penelope_track_maker(
    p,
    steering,
    initial_direction='random',
    wipe_folders=True,
    reset_origin=False,
    fresh_seed=True,
    delete_penelope_data=True,
)

# This script was generated automatically. Do not edit manually.

"""

SBATCH_TEMPLATE = """#!/bin/bash
#SBATCH --job-name=pen_{energy}_{suffix}
#SBATCH --time=02:00:00
#SBATCH --mem=4G
#SBATCH --cpus-per-task=1
#SBATCH --ntasks=1
#SBATCH --output=/dev/null
#SBATCH --error=/dev/null

python {script_dir}/{py_script}
"""

# ========== MAIN SCRIPT ==========

Path(SBATCH_SCRIPT_PATH).mkdir(parents=True, exist_ok=True)

# Calculate total number of jobs for summary
total_jobs = 0
for config in TRACK_CONFIGS:
    energy = config['energy']
    total_tracks = config['num_tracks']
    total_jobs += int(np.ceil(total_tracks / MAX_BATCH))

for config in TRACK_CONFIGS:
    energy = config['energy']
    total_tracks = config['num_tracks']
    num_batches = int(np.ceil(total_tracks / MAX_BATCH))

    for i in range(num_batches):
        n_tracks = min(MAX_BATCH, total_tracks - i * MAX_BATCH)
        suffix = f"batch{i+1}"
        tag = suffix

        py_name = f"run_{energy}keV_batch{i+1}.py"
        sbatch_name = f"submit_{energy}keV_batch{i+1}.sbatch"
        py_path = os.path.join(SBATCH_SCRIPT_PATH, py_name)
        sbatch_path = os.path.join(SBATCH_SCRIPT_PATH, sbatch_name)

        with open(py_path, "w") as f:
            f.write(PYTHON_TEMPLATE.format(
                particles=PARTICLES,
                material=MATERIAL,
                tag=tag,
                energy=energy,
                n_tracks=n_tracks,
                max_batch=MAX_BATCH,
                exec_path=EXECUTABLE_PATH,
                output_path=OUTPUT_PATH
            ))

        with open(sbatch_path, "w") as f:
            f.write(SBATCH_TEMPLATE.format(
                energy=energy,
                suffix=suffix,
                script_dir=SBATCH_SCRIPT_PATH,
                py_script=py_name
            ))

        os.system(f"sbatch {sbatch_path}")
        print(f"‚úÖ Submitted batch {i+1} for {energy} keV")

print(f"\nüì¶ All {total_jobs} jobs launched.")
